{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference Assisted Energy Model Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.metrics import r2_score\n",
    "try:\n",
    "    import inputs \n",
    "except:\n",
    "    import src.inputs as inputs\n",
    "try:\n",
    "    import paths \n",
    "except:\n",
    "    import src.paths as paths\n",
    "\n",
    "from run_DIBS import run_model\n",
    "from SensitivityAnalysis import find_converged_sa_sample_size\n",
    "from run_SA import run_SA\n",
    "from GaussianProcesses import perform_gp_convergence\n",
    "from run_GP_samples import sample_gp\n",
    "from run_GP_train import train_gp\n",
    "from BayesianCalibration import run_calibration\n",
    "from multisimulationFunction import run_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cvrmse_r2(measured, simulated):\n",
    "    '''Calculate CV(RMSE) and R2 for a single simulation run.'''\n",
    "    # n = len(measured)\n",
    "    rmse = np.sqrt(np.mean((simulated - measured)**2))\n",
    "    cvrmse = (rmse / np.mean(measured)) * 100\n",
    "    r2 = r2_score(measured, simulated)\n",
    "    return cvrmse, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_process = time.time()\n",
    "\n",
    "''' INPUTS '''\n",
    "scr_gebaeude_id = 30034001          # Building ID\n",
    "calib_type = 'TRY'                  # AMY: Actual Meteorological Year, TRY: Test Reference Year (works only for Germany)\n",
    "output_resolution = None#'M'             # Time resolution for the metered data and calibration: Y = Yearly, M = Monthly, W = Weekly, etc, None = for TRY version\n",
    "climate_file = None#'AMY_2010_2022.epw'  # Name of the climate file\n",
    "\n",
    "''' OPTIONAL INPUTS '''\n",
    "num_bc_param = 5                    # Number of model parameters to be calibrated\n",
    "SA_Convergence_Required = 'Y'       # Preference to run automatized convergence check for Sensitivity Analysis\n",
    "SA_sampling_lowerbound = 4          # Minimum number of samples (N) for Sensitivity Analysis ((N*(2D+2))). D=Dimensions, number of parameters\n",
    "SA_sampling_upperbound = 9          # Maximum number of samples for Sensitivity Analysis (This limit prevents excessively long runtimes if the sensitivity index parameter order does not converge)\n",
    "GP_Convergence_Required = 'Y'       # Preference to run automatized convergence check for meta-model creation\n",
    "min_gp_samples = 66                # Minimum number of samples for meta-model training\n",
    "max_gp_samples = 100             # Maximum number of samples for meta-model training\n",
    "step_gp = 2                       # Increase in sample size for each new meta-model training\n",
    "rmse_threshold = 0.0007             # RMSE criteria for the meta-model\n",
    "gp_test_size = 25/100               # Proportion of samples for GP to be used for the evaluation of the meta-model\n",
    "training_ratio = 75                 # Percentage of observed data to be used for the calibration\n",
    "draws, tune, chains = 100, 200, 4   # Bayesian Calibration parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' IMPORT DATA '''\n",
    "metered=pd.read_excel(os.path.join(paths.DATA_DIR, 'HeatEnergyDemand_{}_{}.xlsx'.format(scr_gebaeude_id, output_resolution)), index_col=0)\n",
    "nr_train_data = round(metered[1:].shape[0]*training_ratio/100)\n",
    "start_time_cal, end_time_cal = metered.index[0].strftime('%Y-%m-%d %H:%M:%S'), metered.index[nr_train_data].strftime('%Y-%m-%d %H:%M:%S')\n",
    "start_time, end_time = metered.index[0].strftime('%Y-%m-%d %H:%M:%S'), metered.index[-1].strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "''' (0) Process Controll File'''\n",
    "df = pd.DataFrame()\n",
    "df['Name'] = ['Step done', 'Duration time in seconds', 'Other info', 'Other info', 'Other info', 'Other info', 'Other info', 'Other info']\n",
    "ctrl_file = os.path.join(paths.CTRL_DIR, f'process_intermittent_check_{scr_gebaeude_id}_{calib_type}_{output_resolution}_{str(training_ratio)}.xlsx')\n",
    "df.to_excel(ctrl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' (1) DIBS Simulation '''\n",
    "start_calc = time.time()\n",
    "\n",
    "HeatingEnergy_sum = run_model(scr_gebaeude_id, \n",
    "                            climate_file, \n",
    "                            start_time, \n",
    "                            end_time, \n",
    "                            output_resolution, \n",
    "                            training_ratio)   \n",
    "\n",
    "end_calc = time.time()\n",
    "if output_resolution == None:\n",
    "    HeatingEnergy_sum = HeatingEnergy_sum.tolist()\n",
    "else: \n",
    "    HeatingEnergy_sum = HeatingEnergy_sum['HeatingEnergy'].values.tolist()\n",
    "df['DIBS'] = ['DIBS simulation is working', end_calc-start_calc, 'Uncalibrated sim result, kWh: ', f'{HeatingEnergy_sum}', '-', '-', '-', '-']\n",
    "df.to_excel(ctrl_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' (2) Sensitivity Analysis'''\n",
    "if SA_Convergence_Required == 'Y':             \n",
    "    num_samples_sa, sa_converged, calc_time_SA = find_converged_sa_sample_size(scr_gebaeude_id, \n",
    "                                                                               calib_type, \n",
    "                                                                               climate_file, \n",
    "                                                                               start_time_cal, \n",
    "                                                                               end_time_cal, \n",
    "                                                                               output_resolution, \n",
    "                                                                               training_ratio,  \n",
    "                                                                               SA_sampling_lowerbound, \n",
    "                                                                               SA_sampling_upperbound)\n",
    "\n",
    "    ''' No automatized convergence '''\n",
    "else:\n",
    "    sa_converged = 0\n",
    "    num_samples_sa = 32     # Default number of samples for determination of most sensible parameters.\n",
    "    total_SI, calc_time_SA = run_SA(scr_gebaeude_id, num_samples_sa, climate_file, start_time_cal, end_time_cal, output_resolution, training_ratio) \n",
    "        \n",
    "df['SA'] = ['SA is done', f'Convergence time: {calc_time_SA}', f'Num samples: {num_samples_sa}', f'SA Converged: {sa_converged}', f'SA_Convergence_Required: {SA_Convergence_Required}', '-', '-', '-']\n",
    "df.to_excel(ctrl_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GP_Convergence_Required == 'Y':\n",
    "    best_result, best_kernel_path, best_samples_df_path, conv_time = perform_gp_convergence(scr_gebaeude_id, climate_file, output_resolution, calib_type, \n",
    "                                                                                            start_time_cal, end_time_cal, min_gp_samples, max_gp_samples, \n",
    "                                                                                            num_bc_param, num_samples_sa, step_gp, rmse_threshold, \n",
    "                                                                                            gp_test_size, training_ratio)\n",
    "    best_rmse_norm = best_result['RMSE_NORM']\n",
    "    kernel_index = best_result['Kernel_Index']\n",
    "    kernel = best_result['Kernel']\n",
    "    num_samples_gp = best_result['Num_Samples_GP']\n",
    "\n",
    "    df['GP convergence'] = ['GP is done', conv_time, f'num_samples_gp: {num_samples_gp}', f'num_bc_param: {num_bc_param}', f'num_samples_sa: {num_samples_sa}', f'climate_file: {climate_file}', f'output_resolution: {output_resolution}', '-']\n",
    "    df.to_excel(ctrl_file, index=False)\n",
    "\n",
    "    ''' No automatized convergence '''\n",
    "else:\n",
    "    num_samples_gp = 80     # Default number of samples for the training & testing of the meta-model.\n",
    "    kernel, kernel_index = 1 * RationalQuadratic(), 1   # Default Kernel\n",
    "\n",
    "    # Sampling for the Gaussian Processes\n",
    "    start = time.time()\n",
    "    samples_df, calc_time = sample_gp(scr_gebaeude_id, num_bc_param, num_samples_sa, num_samples_gp, climate_file, start_time_cal, end_time_cal, output_resolution, training_ratio)\n",
    "    finish = time.time()\n",
    "    df['GP sample'] = ['GP samples is done', finish-start, f'num_samples_gp: {num_samples_gp}', f'num_bc_param: {num_bc_param}', f'num_samples_sa: {num_samples_sa}', f'climate_file: {climate_file}', f'start_time, end_time: {start_time}, {end_time}', f'output_resolution: {output_resolution}']\n",
    "    df.to_excel(ctrl_file, index=False)\n",
    "        \n",
    "    # Training the meta-model\n",
    "    start = time.time()\n",
    "    kernel_trained, mse, mae, rmse, r2, sigma, y_test_mean, mape = train_gp(scr_gebaeude_id, num_bc_param, kernel, kernel_index, num_samples_gp, gp_test_size, output_resolution, training_ratio) \n",
    "    finish = time.time()\n",
    "    df['GP train'] = ['GP train is done', finish-start, f'bc_param: {num_bc_param}, training_ratio: {training_ratio}, samples: {num_samples_gp}', f'Kernel: {kernel_trained}', f'Kernel index: {kernel_index}, GP test size: {gp_test_size}', f'MAPE: {mape} / MSE: {mse} / RMSE: {rmse} / MAE: {mae}', f'r2-score: {r2}', f'std of prediction: {sigma}']\n",
    "    df.to_excel(ctrl_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' (5) Bayesian Calibration '''\n",
    "from BayesianCalibration import plot_calibration_results\n",
    "threshold = 1.01    # Gelman-Rubin convergence diagnostic criteria\n",
    "kernel_index =1\n",
    "num_samples_gp = 72\n",
    "start = time.time()\n",
    "trace, converged, draws, tune, chains = run_calibration(scr_gebaeude_id, num_bc_param, \n",
    "                                                        draws, tune, chains, \n",
    "                                                        num_samples_gp, kernel_index, \n",
    "                                                        output_resolution,training_ratio, \n",
    "                                                        start_time_cal, end_time_cal, \n",
    "                                                        threshold)\n",
    "\n",
    "if converged:\n",
    "    print(f'Bayesian calibration converged at {tune} tunes and {draws} draws')\n",
    "    summary = plot_calibration_results(scr_gebaeude_id,num_bc_param,\n",
    "                output_resolution,training_ratio,draws=draws,tune=tune,\n",
    "                chains=chains)\n",
    "\n",
    "else:\n",
    "    print(f'Did not converge for training_ratio = {training_ratio}')\n",
    "finish = time.time()\n",
    "\n",
    "df[f'BC training_ratio: {training_ratio}, num_bc_param: {num_bc_param}'] = ['BC is done', finish-start, f'num bc param: {num_bc_param}', f'{tune} tunes, {draws} draws, {chains} chains', f'output resolution: {output_resolution}','-','-','-']\n",
    "df.to_excel(ctrl_file, index=False)\n",
    "\n",
    "\n",
    "\n",
    "finish_process = time.time()\n",
    "print(f'The framework required {(finish_process-start_process)/3600} hours to complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate with Calibrated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from run_calibModel import run_parallel_simulations, create_violin_plot\n",
    "def main():\n",
    "    if converged:\n",
    "        df_params, results_df = run_parallel_simulations(\n",
    "        scr_gebaeude_id,\n",
    "        num_bc_param,\n",
    "        draws,\n",
    "        tune,\n",
    "        chains,\n",
    "        output_resolution,\n",
    "        training_ratio,\n",
    "        start_time,\n",
    "        end_time,\n",
    "        climate_file,\n",
    "        ctrl_file\n",
    "    )\n",
    "        \n",
    "    violin_fig = create_violin_plot(\n",
    "        scr_gebaeude_id,\n",
    "        num_bc_param,\n",
    "        samples,\n",
    "        output_resolution,\n",
    "        training_ratio,\n",
    "        calib_type\n",
    "    )\n",
    "    violin_fig.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    mp.freeze_support()\n",
    "    main()\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_calibModel import run_parallel_simulations, create_violin_plot\n",
    "violin_fig = create_violin_plot(\n",
    "        scr_gebaeude_id,\n",
    "        num_bc_param,\n",
    "        parameters_combination,\n",
    "        output_resolution,\n",
    "        training_ratio,\n",
    "        calib_type\n",
    "    )\n",
    "violin_fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bauSancondaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
